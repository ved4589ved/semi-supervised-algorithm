{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\india\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, losses, metrics, callbacks, datasets\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "seed=42\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using neural net on already labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7239 - accuracy: 0.7643 - val_loss: 0.5211 - val_accuracy: 0.8216\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4842 - accuracy: 0.8321 - val_loss: 0.4352 - val_accuracy: 0.8534\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4388 - accuracy: 0.8455 - val_loss: 0.5341 - val_accuracy: 0.7984\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4121 - accuracy: 0.8565 - val_loss: 0.3916 - val_accuracy: 0.8652\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3937 - accuracy: 0.8619 - val_loss: 0.3747 - val_accuracy: 0.8692\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3751 - accuracy: 0.8675 - val_loss: 0.3712 - val_accuracy: 0.8734\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3631 - accuracy: 0.8714 - val_loss: 0.3626 - val_accuracy: 0.8728\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3517 - accuracy: 0.8751 - val_loss: 0.3859 - val_accuracy: 0.8632\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3412 - accuracy: 0.8792 - val_loss: 0.3589 - val_accuracy: 0.8708\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3320 - accuracy: 0.8825 - val_loss: 0.3432 - val_accuracy: 0.8786\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3240 - accuracy: 0.8841 - val_loss: 0.3430 - val_accuracy: 0.8770\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3148 - accuracy: 0.8866 - val_loss: 0.3309 - val_accuracy: 0.8832\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3080 - accuracy: 0.8895 - val_loss: 0.3278 - val_accuracy: 0.8876\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3021 - accuracy: 0.8915 - val_loss: 0.3427 - val_accuracy: 0.8758\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2946 - accuracy: 0.8937 - val_loss: 0.3212 - val_accuracy: 0.8868\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2889 - accuracy: 0.8973 - val_loss: 0.3098 - val_accuracy: 0.8892\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2840 - accuracy: 0.8971 - val_loss: 0.3558 - val_accuracy: 0.8720\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2777 - accuracy: 0.9004 - val_loss: 0.3136 - val_accuracy: 0.8912\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2729 - accuracy: 0.9027 - val_loss: 0.3123 - val_accuracy: 0.8894\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2674 - accuracy: 0.9034 - val_loss: 0.3285 - val_accuracy: 0.8804\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2625 - accuracy: 0.9057 - val_loss: 0.3053 - val_accuracy: 0.8922\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2578 - accuracy: 0.9075 - val_loss: 0.2969 - val_accuracy: 0.8970\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2536 - accuracy: 0.9080 - val_loss: 0.3002 - val_accuracy: 0.8932\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2487 - accuracy: 0.9104 - val_loss: 0.3093 - val_accuracy: 0.8874\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2444 - accuracy: 0.9130 - val_loss: 0.2982 - val_accuracy: 0.8936\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2406 - accuracy: 0.9139 - val_loss: 0.3081 - val_accuracy: 0.8896\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2365 - accuracy: 0.9157 - val_loss: 0.3031 - val_accuracy: 0.8956\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2328 - accuracy: 0.9167 - val_loss: 0.3014 - val_accuracy: 0.8942\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2286 - accuracy: 0.9187 - val_loss: 0.3049 - val_accuracy: 0.8894\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2253 - accuracy: 0.9188 - val_loss: 0.3026 - val_accuracy: 0.8922\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33530178666114807, 0.882099986076355]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_proba = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_proba, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we will be using semi supervised learning where i will take unlabelled data and label the data using the clustering on the subset of data then will use the supervised learning get the label on all the data. we will validate the accuracy of neural network by checking on already labeled untrained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Use Clustering for label (K mean clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take only X_train dataset and take their subset to make label\n",
    "\n",
    "X_train_subset= X_train[:40000]\n",
    "X_train_subset_flatten= X_train_subset.reshape(X_train[:40000].shape[0],-1)\n",
    "## using clustering on the this subset\n",
    "kmeans = KMeans(init='k-means++', n_clusters=50, random_state=0).fit(X_train_subset_flatten)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=kmeans.labels_  ## label of the subset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## doing test train split for validation\n",
    "X_train_full_new, X_test_new= X_train_subset[:35000],X_train_subset[35000:]\n",
    "Y_train_full_new, Y_test_new= label[:35000], label[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_new, X_train_new = X_train_full_new[:5000], X_train_full_new[5000:]\n",
    "Y_valid_new, Y_train_new = Y_train_full_new[:5000], Y_train_full_new[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(50, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2739 - accuracy: 0.3861 - val_loss: 1.3574 - val_accuracy: 0.5730\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 1.1093 - accuracy: 0.6333 - val_loss: 0.9669 - val_accuracy: 0.6748\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.8300 - accuracy: 0.7040 - val_loss: 0.7501 - val_accuracy: 0.7330\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.6769 - accuracy: 0.7535 - val_loss: 0.6383 - val_accuracy: 0.7700\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5718 - accuracy: 0.7925 - val_loss: 0.5734 - val_accuracy: 0.7798\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.4917 - accuracy: 0.8245 - val_loss: 0.5299 - val_accuracy: 0.7992\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.4301 - accuracy: 0.8480 - val_loss: 0.4279 - val_accuracy: 0.8434\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3860 - accuracy: 0.8620 - val_loss: 0.3790 - val_accuracy: 0.8622\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3455 - accuracy: 0.8772 - val_loss: 0.3746 - val_accuracy: 0.8600\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3197 - accuracy: 0.8872 - val_loss: 0.3221 - val_accuracy: 0.8858\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2948 - accuracy: 0.8981 - val_loss: 0.3170 - val_accuracy: 0.8848\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2811 - accuracy: 0.8991 - val_loss: 0.3292 - val_accuracy: 0.8714\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2609 - accuracy: 0.9092 - val_loss: 0.3055 - val_accuracy: 0.8854\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2473 - accuracy: 0.9139 - val_loss: 0.2582 - val_accuracy: 0.9080\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2405 - accuracy: 0.9150 - val_loss: 0.2377 - val_accuracy: 0.9150\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2293 - accuracy: 0.9190 - val_loss: 0.3029 - val_accuracy: 0.8856\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2175 - accuracy: 0.9239 - val_loss: 0.2365 - val_accuracy: 0.9104\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2115 - accuracy: 0.9252 - val_loss: 0.2430 - val_accuracy: 0.9090\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2062 - accuracy: 0.9274 - val_loss: 0.2279 - val_accuracy: 0.9122\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1955 - accuracy: 0.9315 - val_loss: 0.2454 - val_accuracy: 0.9034\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1898 - accuracy: 0.9332 - val_loss: 0.2149 - val_accuracy: 0.9180\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1864 - accuracy: 0.9353 - val_loss: 0.1883 - val_accuracy: 0.9354\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1832 - accuracy: 0.9347 - val_loss: 0.1955 - val_accuracy: 0.9284\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1762 - accuracy: 0.9375 - val_loss: 0.1948 - val_accuracy: 0.9272\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1643 - accuracy: 0.9431 - val_loss: 0.2114 - val_accuracy: 0.9166\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1695 - accuracy: 0.9385 - val_loss: 0.2082 - val_accuracy: 0.9178\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1636 - accuracy: 0.9434 - val_loss: 0.1863 - val_accuracy: 0.9290\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1652 - accuracy: 0.9427 - val_loss: 0.1993 - val_accuracy: 0.9202\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1506 - accuracy: 0.9480 - val_loss: 0.1730 - val_accuracy: 0.9350\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1492 - accuracy: 0.9477 - val_loss: 0.1900 - val_accuracy: 0.9270\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_new, Y_train_new, epochs=30,\n",
    "                    validation_data=(X_valid_new, Y_valid_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1952732354402542, 0.9193999767303467]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_new, Y_test_new)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acheived a accuracy of 91% by doing labeling on unlabeled data with 50 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## acheive a accuracy of 91% with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_proba_new = model.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 10, 25, ..., 39,  5, 39], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_proba_new, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 10, 25, ..., 39,  5, 28])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "## getting label on data which was not in our subset\n",
    "label_rest= model.predict(X_train[40000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experimenting with different value of cluster\n",
    "### Taking cluster of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_subset_30= X_train[:40000]\n",
    "X_train_subset_flatten_30= X_train_subset_30.reshape(X_train[:40000].shape[0],-1)\n",
    "## using clustering on the this subset\n",
    "kmeans = KMeans(init='k-means++', n_clusters=30, random_state=0).fit(X_train_subset_flatten_30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_30=kmeans.labels_  ## label of the subset data with 30 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## doing test train split for validation\n",
    "X_train_full_new_30, X_test_new_30= X_train_subset_30[:35000],X_train_subset_30[35000:]\n",
    "Y_train_full_new_30, Y_test_new_30= label_30[:35000], label_30[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_new_30, X_train_new_30 = X_train_full_new_30[:5000], X_train_full_new_30[5000:]\n",
    "Y_valid_new_30, Y_train_new_30 = Y_train_full_new_30[:5000], Y_train_full_new_30[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(30, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.6867 - accuracy: 0.5126 - val_loss: 0.9355 - val_accuracy: 0.6920\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.7823 - accuracy: 0.7208 - val_loss: 0.6942 - val_accuracy: 0.7368\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5925 - accuracy: 0.7815 - val_loss: 0.5432 - val_accuracy: 0.7888\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.4834 - accuracy: 0.8212 - val_loss: 0.4417 - val_accuracy: 0.8398\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4047 - accuracy: 0.8528 - val_loss: 0.3812 - val_accuracy: 0.8586\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3474 - accuracy: 0.8745 - val_loss: 0.3633 - val_accuracy: 0.8636\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.3038 - accuracy: 0.8940 - val_loss: 0.3245 - val_accuracy: 0.8734\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2756 - accuracy: 0.8997 - val_loss: 0.3048 - val_accuracy: 0.8768\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2498 - accuracy: 0.9110 - val_loss: 0.2506 - val_accuracy: 0.9096\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2297 - accuracy: 0.9200 - val_loss: 0.2514 - val_accuracy: 0.9034\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2168 - accuracy: 0.9216 - val_loss: 0.2239 - val_accuracy: 0.9142\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2063 - accuracy: 0.9271 - val_loss: 0.2345 - val_accuracy: 0.9060\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1901 - accuracy: 0.9321 - val_loss: 0.1935 - val_accuracy: 0.9298\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1822 - accuracy: 0.9346 - val_loss: 0.1866 - val_accuracy: 0.9328\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1734 - accuracy: 0.9383 - val_loss: 0.1909 - val_accuracy: 0.9272\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1692 - accuracy: 0.9403 - val_loss: 0.1918 - val_accuracy: 0.9190\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1605 - accuracy: 0.9435 - val_loss: 0.2044 - val_accuracy: 0.9182\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1574 - accuracy: 0.9447 - val_loss: 0.1845 - val_accuracy: 0.9322\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1576 - accuracy: 0.9448 - val_loss: 0.2075 - val_accuracy: 0.9122\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1446 - accuracy: 0.9485 - val_loss: 0.2157 - val_accuracy: 0.9108\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1437 - accuracy: 0.9503 - val_loss: 0.1645 - val_accuracy: 0.9324\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1391 - accuracy: 0.9503 - val_loss: 0.1482 - val_accuracy: 0.9394\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1267 - accuracy: 0.9561 - val_loss: 0.1838 - val_accuracy: 0.9226\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1243 - accuracy: 0.9599 - val_loss: 0.1571 - val_accuracy: 0.9360\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1272 - accuracy: 0.9553 - val_loss: 0.2010 - val_accuracy: 0.9132\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1217 - accuracy: 0.9582 - val_loss: 0.2103 - val_accuracy: 0.9154\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1153 - accuracy: 0.9612 - val_loss: 0.1570 - val_accuracy: 0.9374\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1176 - accuracy: 0.9607 - val_loss: 0.1429 - val_accuracy: 0.9406\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1159 - accuracy: 0.9622 - val_loss: 0.1660 - val_accuracy: 0.9364\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1115 - accuracy: 0.9622 - val_loss: 0.1570 - val_accuracy: 0.9414\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_new_30, Y_train_new_30, epochs=30,\n",
    "                    validation_data=(X_valid_new_30, Y_valid_new_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15311087667942047, 0.9362000226974487]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_new_30, Y_test_new_30)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "## getting label on data which was not in our subset\n",
    "label_rest= model.predict(X_train[40000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## after taking a value of K=30 achieve a accuracy of 94%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_subset_10= X_train[:40000]\n",
    "X_train_subset_flatten_10= X_train_subset_10.reshape(X_train[:40000].shape[0],-1)\n",
    "## using clustering on the this subset\n",
    "kmeans = KMeans(init='k-means++', n_clusters=10, random_state=0).fit(X_train_subset_flatten_10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_10=kmeans.labels_  ## label of the subset data with 30 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## doing test train split for validation\n",
    "X_train_full_new_10, X_test_new_10= X_train_subset_10[:35000],X_train_subset_10[35000:]\n",
    "Y_train_full_new_10, Y_test_new_10= label_10[:35000], label_10[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_new_10, X_train_new_10 = X_train_full_new_10[:5000], X_train_full_new_10[5000:]\n",
    "Y_valid_new_10, Y_train_new_10 = Y_train_full_new_10[:5000], Y_train_full_new_10[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 4s 3ms/step - loss: 0.6654 - accuracy: 0.7635 - val_loss: 0.3808 - val_accuracy: 0.8578\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3300 - accuracy: 0.8727 - val_loss: 0.2711 - val_accuracy: 0.9004\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2492 - accuracy: 0.9070 - val_loss: 0.2246 - val_accuracy: 0.9164\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2036 - accuracy: 0.9215 - val_loss: 0.2025 - val_accuracy: 0.9230\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1740 - accuracy: 0.9358 - val_loss: 0.1596 - val_accuracy: 0.9402\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1541 - accuracy: 0.9434 - val_loss: 0.2547 - val_accuracy: 0.8970\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1361 - accuracy: 0.9503 - val_loss: 0.1920 - val_accuracy: 0.9194\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1248 - accuracy: 0.9558 - val_loss: 0.1233 - val_accuracy: 0.9536\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1148 - accuracy: 0.9598 - val_loss: 0.1131 - val_accuracy: 0.9568\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1092 - accuracy: 0.9604 - val_loss: 0.1077 - val_accuracy: 0.9594\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1029 - accuracy: 0.9635 - val_loss: 0.1189 - val_accuracy: 0.9528\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0946 - accuracy: 0.9660 - val_loss: 0.0984 - val_accuracy: 0.9622\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0900 - accuracy: 0.9677 - val_loss: 0.0892 - val_accuracy: 0.9662\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0878 - accuracy: 0.9693 - val_loss: 0.1013 - val_accuracy: 0.9580\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0812 - accuracy: 0.9710 - val_loss: 0.0875 - val_accuracy: 0.9658\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0782 - accuracy: 0.9729 - val_loss: 0.0999 - val_accuracy: 0.9582\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0750 - accuracy: 0.9733 - val_loss: 0.1037 - val_accuracy: 0.9540\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0727 - accuracy: 0.9740 - val_loss: 0.1097 - val_accuracy: 0.9564\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0702 - accuracy: 0.9757 - val_loss: 0.0873 - val_accuracy: 0.9644\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0670 - accuracy: 0.9774 - val_loss: 0.0791 - val_accuracy: 0.9714\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0643 - accuracy: 0.9776 - val_loss: 0.0740 - val_accuracy: 0.9746\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0615 - accuracy: 0.9792 - val_loss: 0.0814 - val_accuracy: 0.9686\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0603 - accuracy: 0.9797 - val_loss: 0.0743 - val_accuracy: 0.9700\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0600 - accuracy: 0.9802 - val_loss: 0.0732 - val_accuracy: 0.9706\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.0809 - val_accuracy: 0.9662\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0567 - accuracy: 0.9800 - val_loss: 0.0718 - val_accuracy: 0.9714\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0516 - accuracy: 0.9827 - val_loss: 0.0703 - val_accuracy: 0.9718\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0565 - accuracy: 0.9811 - val_loss: 0.0921 - val_accuracy: 0.9582\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.1039 - val_accuracy: 0.9594\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0513 - accuracy: 0.9827 - val_loss: 0.0821 - val_accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_new_10, Y_train_new_10, epochs=30,\n",
    "                    validation_data=(X_valid_new_10, Y_valid_new_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0942617803812027, 0.9581999778747559]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_new_10, Y_test_new_10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "## getting label on data which was not in our subset\n",
    "label_rest= model.predict(X_train[40000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking K=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_subset_100= X_train[:40000]\n",
    "X_train_subset_flatten_100= X_train_subset_100.reshape(X_train[:40000].shape[0],-1)\n",
    "## using clustering on the this subset\n",
    "kmeans = KMeans(init='k-means++', n_clusters=100, random_state=0).fit(X_train_subset_flatten_100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_100=kmeans.labels_  ## label of the subset data with 100 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## doing test train split for validation\n",
    "X_train_full_new_100, X_test_new_100= X_train_subset_100[:35000],X_train_subset_100[35000:]\n",
    "Y_train_full_new_100, Y_test_new_100= label_100[:35000], label_100[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_new_100, X_train_new_100 = X_train_full_new_100[:5000], X_train_full_new_100[5000:]\n",
    "Y_valid_new_100, Y_train_new_100 = Y_train_full_new_100[:5000], Y_train_full_new_100[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(200, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 3.4466 - accuracy: 0.1956 - val_loss: 2.3373 - val_accuracy: 0.3426\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8359 - accuracy: 0.4640 - val_loss: 1.5523 - val_accuracy: 0.4966\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.3162 - accuracy: 0.5813 - val_loss: 1.2295 - val_accuracy: 0.5842\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.0646 - accuracy: 0.6488 - val_loss: 0.9912 - val_accuracy: 0.6666\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.9075 - accuracy: 0.6904 - val_loss: 0.8768 - val_accuracy: 0.6906\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.7858 - accuracy: 0.7287 - val_loss: 0.7790 - val_accuracy: 0.7272\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.6890 - accuracy: 0.7592 - val_loss: 0.7280 - val_accuracy: 0.7334\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.6085 - accuracy: 0.7865 - val_loss: 0.6074 - val_accuracy: 0.7866\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.5439 - accuracy: 0.8108 - val_loss: 0.5654 - val_accuracy: 0.7980\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4911 - accuracy: 0.8300 - val_loss: 0.5300 - val_accuracy: 0.8092\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4502 - accuracy: 0.8449 - val_loss: 0.4968 - val_accuracy: 0.8226\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.4142 - accuracy: 0.8575 - val_loss: 0.4368 - val_accuracy: 0.8514\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.3837 - accuracy: 0.8702 - val_loss: 0.4709 - val_accuracy: 0.8246\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3627 - accuracy: 0.8773 - val_loss: 0.4312 - val_accuracy: 0.8382\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.3416 - accuracy: 0.8829 - val_loss: 0.4070 - val_accuracy: 0.8472\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.3267 - accuracy: 0.8885 - val_loss: 0.3614 - val_accuracy: 0.8684\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3074 - accuracy: 0.8950 - val_loss: 0.4451 - val_accuracy: 0.8236\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2925 - accuracy: 0.9014 - val_loss: 0.3410 - val_accuracy: 0.8732\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2854 - accuracy: 0.9015 - val_loss: 0.3515 - val_accuracy: 0.8662\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2707 - accuracy: 0.9096 - val_loss: 0.4538 - val_accuracy: 0.8244\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2629 - accuracy: 0.9113 - val_loss: 0.3406 - val_accuracy: 0.8726\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2577 - accuracy: 0.9120 - val_loss: 0.3149 - val_accuracy: 0.8800\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2445 - accuracy: 0.9158 - val_loss: 0.3317 - val_accuracy: 0.8760\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2402 - accuracy: 0.9181 - val_loss: 0.3045 - val_accuracy: 0.8844\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2321 - accuracy: 0.9203 - val_loss: 0.3106 - val_accuracy: 0.8808\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2210 - accuracy: 0.9262 - val_loss: 0.2873 - val_accuracy: 0.8922\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2197 - accuracy: 0.9260 - val_loss: 0.2996 - val_accuracy: 0.8814\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2125 - accuracy: 0.9281 - val_loss: 0.2882 - val_accuracy: 0.8908\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2088 - accuracy: 0.9301 - val_loss: 0.2925 - val_accuracy: 0.8862\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2030 - accuracy: 0.9320 - val_loss: 0.2781 - val_accuracy: 0.8972\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_new_100, Y_train_new_100, epochs=30,\n",
    "                    validation_data=(X_valid_new_100, Y_valid_new_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27845636010169983, 0.8920000195503235]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_new_100, Y_test_new_100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with cluster of 100 we will get the accuarcy of 88.86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "## getting label on data which was not in our subset\n",
    "label_rest= model.predict(X_train[40000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if we decrease the cluster size accuracy will increase but no of labels will decrease which will not be a good classification as it will classify two different object in same label, but if we incrase the label I.e. the cluster size then accuracy of classification in different label will decrease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
